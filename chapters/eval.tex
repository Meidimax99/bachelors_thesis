\chapter{Evaluation}
\label{chap:eval}

% -------------------------------------------------------------------------------------------------
%                                             Structure
% -------------------------------------------------------------------------------------------------



% Qualitative Analysis (Does not need a heading, the whole chapter is about this)

% - Cost of the design
%     - Context Switch (Just general cost, specifics later)
%         jacobVirtualMemoryContemporary1998 -> Pipeline flushing etc
%     - Exception Handler
%     - Optimization Opportunities
%         - Heisers Fast TLB Miss handler
%         - Inlining

% - General problems of a Segmented Design

% - More shortcommings related to the functional requirements of virtual memory
%     (Resolve shortcommings?)

% - Qualitative Cost analysis
%     - Problems with acquiring quantitative data from QEMU
%         - Typical Metrics (and if they can be acquired from qemu)
%             - Instruction Count
%             - Cycle count
%         - Real hardware: Comparing Cycle count, or measuring ms (-> MMU freezes the CPU)
%     - Mem Access Counting (Instruction counting?)

% - Smoothing out the implementation
% - handler inlining
% - Better control using MIPS TLB instructions


% -------------------------------------------------------------------------------------------------
%                                             Software-Managed TLBs
% -------------------------------------------------------------------------------------------------
\section{Software-managed TLBs}
Managing TLBs in software grants a lot of flexibility, but this flexibility does not come
for free. While the general trade-offs between software and hardware TLB managements have
already been discussed in the Fundamentals chapter \ref{chap:fund}, this section will
go into more detail of the trade-offs of this specific design and implementation.

\subsection{Context Switch} The fast TLB miss handler presented by Gernot Heiser for the
L4/MIPS implementation only uses three registers: Two of those registers are reserved
for the kernel and the other one has to be saved in memory to later be restored \cite{heiserAnatomyHighPerformanceMicrokernel}.
While the processor still has to run the instructions, this is only minimally invasive
for the state of the kernel.

This implementation performs a complete save of the processor state, including most of the
32 registers that RISC-V offers.
This allows running C code from the exception handler without having the think about what
registers are mangled by the code, which is very useful for trying different implementations.
The tradeoff here lies between ease of programmability and performance.

\subsection{Pipeline Flush} Exception handlers not only change the state of the processor that is
exposed to the programmer, they also disturb the transparent state consisting of the
instruction pipeline and the reorder buffer.
Running instructions from the context of the exception handler (coupled with RISC-V handling
memory faults precisely \cite{RISCVInstructionSet}) requires a flush of both reorder buffer
and instruction pipeline \cite{jacobVirtualMemoryContemporary1998}.
Instructions that have already been partially executed in the pipeline have to be restarted,
imposing extra cost on the software handler \cite{jacob1998look}.

\subsection{Exception Handler} The key difference of this exception handler and exception handlers
of other software-based virtual memory designs is that this one does not need to access
memory to generate mappings (apart from the register state save).
Looking back at listing \ref{Final Handler Code} it is apparent that there still are some
memory references:
Mostly the function call of the \texttt{get\_mapping()} function would generate code that
writes to the stack. But the function call is only for readability of the code and could also
be inlined.
Otherwise the implementation is based on calculation for determining the memory offset from
the ASID and bitwise operations.
This is an advantage over radix page table systems that may need up to five memory references
in contemporary architectures \cite{intel5LevelPaging5Level2017}.

% \todo{typical tlb replacement strategies}
% \todo{How does QEMU replace TLB entries -> index?} % Direct mapped
% With the new CSRs presented above, it is possible to write TLB entries.
% The placement of the entry and thus the entry to be replaced can not be selected.
% The replacement policy would be completely up to the hardware implementation.
% It would also be possible to further extend the ISA with additional CSRs to
% support specific selection of entries to be replaced, or to select between
% a number of replacement strategies.
% However, the efficiency of more complex strategies need to be weighed carefully
% against their benefits, since the TLB filling is on the critical path of all
% memory accesses.
% -------------------------------------------------------------------------------------------------
%                                             Segmented VM Desing (Design shortcommings)
% -------------------------------------------------------------------------------------------------
\section{Segmented Memory Design}
The segmented mapping function design has some fundamental problems that restrict
% Generall Segmented Design shortcommings
% Allgemeine Discussion eines Segmentierten Designs
% \cite{skarlatos2020elastic}
% \cite{tanenbaumOS}
% \cite{denning1997before}??
% TODO [denningVirtualMemoryDenning1996] -> Overlay problem with segmented designs


% Restrictions of the Segmented design ( da kann ich auch allgemeine Punkte zu segmentierten
% speicherdesigns aus grundlagendpapern rausnehmen)

%Flexibility limitation -> flexibility of the virtual memory system
% is still restricted by the tlb structure
% -> other approach jacobSoftwaremanagedAddressTranslation1997

% More fine grained controll over TLBs via CSRs -> Inspo mips ( Evaluation of Implementation, not necesarrily design)

\paragraph*{Fragmentation}
%Processes have fixed size of memory and may not use all of it

\paragraph*{Limited Process count}
%Maybe appropiate for embedded applications?

% Shortcomming: Access rights, no internal segmentation of segments
%  With segmentation it would still be relatively cheap to add a table structure that supports access rights ( in a statically allocated scheme)
%-------------------------------------------------------------------------------------------------
%                                             Functional Requirements
% -------------------------------------------------------------------------------------------------
\section{Memory System Requirements}
% Shortcommings of my implementation
For a quantitative assessment of the design, the functional requirements to virtual memory system from chapter \ref{chap:fund} are revisited.

\paragraph{Address Space Protection / Isolation} Since all memory accesses from virtual addresses go through the TLB, a proper isolation of processes in the TLB exception handler guarantees isolation of processes. ASIDs are used as the foundation of address calculation to provide each process with a distinct physical memory space.
Synchronization on the data structure managing ASIDs makes sure that no two processes can have the same ASID while both are alive.

\paragraph{Large Address Space} Segmentation restricts the maximum size each process can have. One could implement dynamic resizing of address spaces or allow processes to hold multiple ASIDs to allow processes to increase their memory over the statically determined maximum limit.
That would however increase the complexity of the mapping function. Another idea would be to have address spaces with different (predetermined) sizes that could than assigned according to a programs memory demands.

\paragraph{Superpages} The current state of the design does not really deal in pages but rather in complete address spaces. As such, super pages are not supported.

\paragraph{Flexibility} Pages in the virtual memory space can be placed anywhere as long as they are within the maximum address space size. And they must not clash with the heap space that will always be expanding from low to high addresses.

\paragraph{Sparsity} Sparsity in page table based virtual memory systems is about efficiently
supporting hugh address spaces with only a small numbers of pages being actually used. The bookkeeping should use as little additional memory as possible.

The stateless design requires no tables to store the bookkeeping for the mapping - there is no bookkeeping. However, huge address spaces are not supported and the internal fragmentation if very high.

\paragraph{Swapping} One of the most important tasks of a virtual memory system is to automate the swapping of memory pages between main memory and secondary storage. xv6 does not provide a good starting point to experiment with new virtual memory systems that also fulfil that requirement, as xv6 does not implement page swapping. Programs are completely held in memory and also loaded completely into memory on execution \cite{cox2011xv6}. As such, page table faults of any kind will result in xv6 killing the process.

% Was ist mit dem paging passiert -> Automatisches Tauschen von Seiten zwischen Haupt und Nebenspeicher?
% In xv6 nicht implementiert, könnte es mit dem Segmentierten Design implementiert werden

% TODO -> Perspektive richtung Embedded, wo isolation gewünscht aber kein Nebenspeicher existiert
% Idee -> Address spaces with different sizes, so that slots can be swapped, or address spaces can be merged


% -------------------------------------------------------------------------------------------------
%                                             Cost Analysis
% -------------------------------------------------------------------------------------------------
\section{Cost Analysis}
In the implementation, the cost introduced by memory accesses are very high, because the whole state of the register file is saved to memory. That is an unacceptable cost for a operation that is on the critical path of every TLB miss. It is however possible to omit most of these memory accesses in favor of a light-weight TLB miss handler similar to the fast TLB miss handler in \cite{heiserAnatomyHighPerformanceMicrokernel}. The main difference being that the TLB miss handler in \cite{heiserAnatomyHighPerformanceMicrokernel} performs a page table walk and has thus access main memory. An optimized implementation of the mapping function can work with only a small number of register.

To omit all memory accesses from the handler, some registers may be reserved to be only used by kernel code, as MIPS does it with two registers. However, compilers would have to be made aware of that. Depending on the application, reserving registers may still result in a loss of performance because the availability of registers is imperative to the compilers ability to optimize code \cite{elphinstone2013l3}.

Even when all memory references can be eliminated from the handler code, it would still impact both the pipeline and the reorder buffer \cite{jacobSoftwaremanagedAddressTranslation1997}.

% TODO CONT here


% Context Switch
% -> Inline Handler + Vergleich mit größe de Heiser fast TLB miss handlers
% Annahme: Mein TLB miss handler/mapping function könnte sehr klein sein wenn sie
% nur sehr gut optimiert wird und dann könnte man sie eventuell inlinen!
% Hardware Freeze on HW MMU Walk (but independent instruktions can go on -> issues of impl)

% Passt das in eine Cache line -> code localität


% Theoretische Kostenanalyse -> context switch in sw (ausblick inline?)
% -> Optimization -> Reserve Registers for kernel handler, but this wont be good
% -> l4 20 year paper -> registeres important for optiization

% \section{Other operating system features in light of the segmented design}
% TODO discussion (extra chapter?) about whether fork makes sense with
% this segmented allokation approach

% Instruction Count, Software Page Walk vs TLB manager

% switching to kernel evicts other cache entries for kernel in real hardware

% Warum geht quantitativ  nicht -> Emuliert

% Ohne caches -> Emualtion vs Real Hardware -> Warum keine quantitaive analyse

% -------------------------------------------------------------------------------------------------
%                                        Implementation Shortcommings
% -------------------------------------------------------------------------------------------------

\section{Potential Implementation Improvements}
% -------------------------------------------------------------------------------------------------
% -------------------------------------------------------------------------------------------------
% -------------------------------------------------------------------------------------------------
% -------------------------------------------------------------------------------------------------
% -------------------------------------------------------------------------------------------------


% -------------------------------------------------------------------------------------------------


% -------------------------------------------------------------------------------------------------

%
% -------------------------------------------------------------------------------------------------


% vs demand paging





