\chapter{Related Work}

\label{chap:related}
This work can be broadly classified to be in the field of Virtual Memory optimization. There is a large body of literature that deals with optimizing the VM system, as it lies on the critical path of every memory operation.

There are different approaches or perspectives to addressing the system (this is not an exhaustive list):

\begin{itemize}
    \item page table structures and their optimization, e.g., inverted or hierarchical
    \item caching of pages, PTEs in the TLB, and cache indexing
    \item cache replacement strategies
    \item cache sizes, associativity of caches
    \item Page Walk Caches (PWCs) to store partial translation results
\end{itemize}


% -------------------------------------------------------------------------------------------------

% Guarded Page Tables
\textbf{\cite{liedtkeGPT}} shows an innovative design leveraging the flexibility of software-managed
address translation.
The design of Guarded Page Tables (GPTs) is based on hierarchical page tables, but allows skipping over levels of the table to reach translation results faster.
This proves to be very effective for increasing the performance of Virtual Memory systems, as the biggest penalty comes from page tables walks needing to reference memory for every level in the page table.
Gernot Heiser showcases a practical implementation of GPTs in the L4/MIPS system \cite{heiserAnatomyHighPerformanceMicrokernel}.



% -------------------------------------------------------------------------------------------------

% In Cache Software Managed Address Translation
\textbf{\cite{jacobSoftwaremanagedAddressTranslation1997}} explores software-managed address translation and analyses the efficiency of a PowerPC implementation
of the presented design they call \textit{softvm}. They show that
software-managed address translation can achieve better performance and
at the same time simplify hardware by dispensing with translation caches and
the hardware state-machine for walking the page table.
The approach is based on handling virtually indexed and tagged cache misses in
software.
With sufficiently sized virtual caches the system can go for long periods
without requiring translations.
Not unlike this paper, they extend the PowerPC architecture by two new instructions
to write entries to the cache. However, their design uses software page table
walks to find translations on cache-miss, while the approach presented in this
paper presents a software-based TLB fill mechanism with segmented
memory allocation.

% -------------------------------------------------------------------------------------------------

% Translation Caching skip dont walk -> Translation Caches
\textbf{\cite{barrTranslationCachingSkip}} examines the design space of translation caches in MMUs. These caches are not the same as TLBs: TLBs contain full translation results, while the translation caches considered here contain partial translations. In the case of a cache hit, these partial translations allow the system to skip individual steps when traversing the page table tree, thereby saving one or more memory accesses. Otherwise, each level of translation requires a memory reference. These caches are also referred to as Page Walk Caches (PWC) \cite{yaniv2016hash}.

The specific translation cache designs of AMD and Intel platforms are examined and compared to three other designs proposed by the authors. Barr et al. conclude that radix page tables, by caching entries at higher page table levels, can outperform inverted page table designs.

PWCs are out of scope for this thesis, but might be examined in future work with the mapping function approach. This work focuses on optimizing the memory path by eliminating page tables and using a software-controlled TLB, and it does not further consider caches aside from the TLB.



% -------------------------------------------------------------------------------------------------

% Hash don't Cache
\textbf{\cite{yaniv2016hash}} challenges the results of \cite{barrTranslationCachingSkip} and argues that the obtained results are based on a suboptimal implementation of the inverted page table.

They conclude that a well-optimized inverted page table can outperform a radix page table equipped with PWCs. However, they also address the conceptual disadvantages of inverted page tables. For example, it is more difficult to implement superpages.

The work takes a closer look at the differences between various page table designs and the requirements of a memory system (such as superpages or page sharing). These requirements are also important for the design presented here. However, this work aims to avoid using page table structures altogether.


% -------------------------------------------------------------------------------------------------

% Every walk’s a hit: making page walks single-access cache hits
\textbf{\cite{park2022every}} identifies that today’s memory capacities far exceed the coverage of TLBs, causing memory-hungry applications to suffer from frequent page table walks (PTWs).

Two approaches are presented to reduce the associated costs: The first approach aims to reduce the number of memory references per PTW by combining two levels of the page table into one. The second approach modifies the cache replacement policy so that cache entries containing PTEs are more likely to remain in the cache during periods with many TLB misses, allowing PTWs to run directly from the cache instead of being loaded from main memory.

They show a 2.3\% performance improvement from flattening the page table tree, 6.2\% through cache prioritization, and a combined performance improvement of 9.2\%. Both approaches focus on optimizing access to page table structures and are separate from this work, as this work aims to eliminate these structures entirely.


% -------------------------------------------------------------------------------------------------

% Elastic Cuckoo Page Table
\textbf{\cite{skarlatos2020elastic}} presents a novel page table design called \textit{Elastic Cuckoo Page Tables}. The design exploits memory-level parallelism to enable fully parallel page table lookups. At the core of the design is the Elastic Cuckoo Hashing algorithm, which allows multiple hashing locations for a given element and enables efficient, gradual resizing of the hash table. Skarlatos et al. demonstrate an application execution speedup of 3-18\% using the Elastic Cuckoo Page Table design.



% -------------------------------------------------------------------------------------------------

\cite{zagieboylo2020cost} proposes an approach that shifts responsibilities of memory management in
parts back to the applications: All applications get a fixed-size chunks of physical memory and then have to manage allocations across these blocks.
Thus, the task of memory management with the chunks falls to compilers, language runtimes and the applications themselves.
This approach does not require any address translation and thus gets completely rid of the overhead associated with the VM system.
Common features of Virtual Memory, like memory space protection can still be implemented with physical memory protection mechanisms present on commodity hardware.
Overall, this approach trades a reduction for complexity of the hardware with increased complexity on the software side.

The design presented in this paper resorts to bigger segments per process, but generally aims to keep the memory management responsibilities with the operating system.

% -------------------------------------------------------------------------------------------------

\cite{halbuer2023morsels} argues that prevailing memory management system designs are becoming increasingly inefficient given modern systems that have very big main memories and workloads that require large in-memory data sets.
The paper presents a novel approach addressing the limitations of current methods with \emph{Morsels}.
These Morsels are self-contained memory objects, spanning entire page table sub-trees, thus allowing efficient remapping, sharing and reducing memory overhead.
They reuse existing interfaces and work on top of existing page table structures to provide a supplementary layer to improve the efficiency of memory-intensive applications.

% -------------------------------------------------------------------------------------------------

The related work presented here focuses on optimizing current page table designs and their hardware
support. This work will explore the feasibility of implementing Virtual Memory without any page table whatsoever using a specialized mapping function to generate virtual to physical mappings.
This promises to reduce the overhead of TLB misses caused by expensive main memory access.

