\chapter{Fundamentals} % Main chapter title
\label{chap:fund}

% Hier muss alles rein was benötigt wird um die Arbeit zu verstehen.
%   Man kann ja sicherlich grundlegendes Verständis von Recherstrukturen und Organisation vorraussetzten
%   Was also sollte definitiv nochmal erklärt werden?
%
%   - Virtual Memory -> Und vor allem die Kosten, das ist ja auch irgendwo der Aufhänger
%           Der Satz, "tlb is on the critical path of everything really" sollte irgendwann mal kommen
%   - Motivation für vm
%   - Organisationsstrukturen auch im vergleich -> Fazit: Page Tables sind überall und werden tiefer -> vor allem wegeb backwards compatiblity?
%   - Hardware Strukturen für VM - MMU, TLB
%   - Operating system and VM -> Implemented by OS but fixed structures given by MMU
%   -> Problem, fehlende flexibilität ->  A look at several ...
%   -> source: Architectural and operating system support for virtual memory
%   source: issues of implementation

% -------------------------------------------------------------------------------------------------
% A little bit of history?? -> [Denning VM '96] -> Altas
% -------------------------------------------------------------------------------------------------

% -------------------------------------------------------------------------------------------------
%                                           VIRTUAL MEMORY
% -------------------------------------------------------------------------------------------------

This chapter introduces some essential concepts and mechanism which form the basis of the following
chapters. It first gives an overview of \textit{Virtual Memory}, its core requirements,
tradeoffs and implementations.\\
Then the hardware components and caches used to accelerate \textit[Virtual Memory] systems are
presented.\\
An overview of purely software-managed systems follows with a comparison of the general trade-offs
between software-managed and hardware-managed \textit{Virtual Memory} systems.\\
Finally, some specifics of the memory system of the chosen implementation platform, \textit{RISC-V},
are shown.

\section{Virtual Memory}
\textit{Virtual Memory} was first introduced in the Atlas System \cite{fotheringham1961dynamic} to
automate the task of swapping pages between main and secondary memory.
The idea was to make the programms completely unaware of of the real, physical memory by providing
an abstraction layer called virtual memory \cite{denning1996virtual}.\\
With virtual memory, programs appear to have the whole memory space of the machine at their disposal (flexibility) and
nobody to share it with (isolation).\\
The task of managing a programs memory, no matter where in its virtual address space it is, and putting it somewhere
in physical memory now falls to the operating system \cite{denning1970virtual}.\\
This was not only a nice-to-have, but a necessity. The size of programs was increasing faster than the size of main
memory did; while single programs
still fit in memory, operating systems allowed running multiple programs at once, collectively exceeding
the available physical memory \cite{tanenbaumOS}.
% -------------------------------------------------------------------------------------------------

\subsection{Virtual and physical addresses}
The terms of \textit{Virtual} and \textit{Physical} addresses will be coming up a lot in the course of this paper.
Virtual addresses refer to the addresses that are used by the program to reference memory object in its address
space. They are only valid in the programs own address space and may thus be reused by different programs.
Virtual addresses are translated to physical addresses, which are actual addresses to memory locations
on main memory. The \textit{Virtual Memory System} is tasked with performing this translation, creating mappings
and keeping book of those mappings.
\\
Some memory systems using an inverted page tables also use the notion of \textit{effective} addresses.
These form an addition layer of indirection that allows the sharing of pages \cite{jacob1998virtualissues}.\\
Effective addresses will not be discussed here any further.
% -------------------------------------------------------------------------------------------------

\subsection{Memory System Requirements}
In modern systems, \textit{Virtual Memory} does a lot more than swapping pages between main memory and secondary
storage. It is the foundation for a number of requirements to the memory system that are taken for granted
\cite{jacobSoftwaremanagedAddressTranslation1997}.\\
These requirements are as follows:

% -------------------------------------------------------------------------------------------------

\paragraph{Address Space Protection / Isolation} It should not be possible for one process to access the data
of another process, unless explicitly shared.
\cite{jacobVirtualMemoryContemporary1998}

% -------------------------------------------------------------------------------------------------

\paragraph{Shared Memory} Sharing memory allows programms to work on the same physical data with potentially
differing virtual addresses.
\cite{jacobVirtualMemoryContemporary1998}

\begin{marginfigure}
    \includegraphics*[width=1\marginparwidth]{figures/fund_share.pdf}
    \caption{\textbf{Page Sharing}}
\end{marginfigure}

% -------------------------------------------------------------------------------------------------

\paragraph{Large Address Spaces} Programs tend to require more and more memory. Swapping pages can help
to support programs bigger than the actual size of main memory \cite{tanenbaumOS}, but programs may
also require more memory than the theoretical limit set by hardware and software. Modern architectures
use bigger addresses to support programs that require a lot of memory \cite{jacobSoftwaremanagedAddressTranslation1997, jacobVirtualMemoryContemporary1998}.

\todo{pages already definied?}
% -------------------------------------------------------------------------------------------------

\paragraph{Fine-grained Protection} From a security perspective, it is often not desirable to allow the code segment
of a program to be writeable and the data section to be exectuable. \textit{Virtual Memory Systems} provide read-only,
read-write and exectue-only protection on a page granularity\cite{jacobSoftwaremanagedAddressTranslation1997}.
Illegal references may trigger exceptions, which allow the operating system to deal with the program \cite{jacobVirtualMemoryContemporary1998}.

\todo{more on tlb reach in HW section}
% -------------------------------------------------------------------------------------------------

\paragraph{Superpages}
Structures may be bigger than a single page and may thus occupy multiple entries of the translation caches while
only refering to one object. To avoid displacing other caches entries, \textit{Virtual Memory Systems} use
superpages to provide space for bigger objects to increase the reach of cache entries \cite{jacobSoftwaremanagedAddressTranslation1997}.

% -------------------------------------------------------------------------------------------------

\paragraph{Flexibility} Programmers should not have to think about the management
of the resources it requires to do its job, that is the ooperating systems job
\cite{tanenbaumOS}. As such, it should be possible to place the programs code
and data anywhere in the programs virtual address space to make the programmers
job as easy as possible
\cite{jacob1998virtualissues}. % Simplification of the programmes job

\begin{marginfigure}
    \includegraphics*[width=0.9\marginparwidth]{figures/fund_flexibility.pdf}
    \caption{\textbf{Flexibility} Program segments can be dispersed anywhere
        around the virtual address space; the Virtual Memory System has to place
        the pages into actual physical memory.}
\end{marginfigure}
% -------------------------------------------------------------------------------------------------

\paragraph{Sparsity} Big addresses and fine granularity result in a huge address
space with a sparse population for programs that do not require a lot of pages
\cite{tanenbaumOS}.

\begin{marginfigure}
    \centering
    \includegraphics*[width=0.5\marginparwidth]{figures/fund_sparsity.pdf}
    \caption{\textbf{Sparsity / Large Address Spaces} Virtual Memory Systems need to efficiently
        realize huge address spaces with only a few pages being used.}
\end{marginfigure}

% -------------------------------------------------------------------------------------------------

% \paragraph{Memory Mapped IO}
% \cite{tanenbaumOS}

Durch das immer weiter Auseinanderdriften der CPU und Memory geschwindigkeiten und vor allem
durch das größer werden von Addressräumen (von 32 auf 64 bit!) \todo{cite} sind die Ansprüche an
das Virtual Memory system gewachsen und so mussten sich auch die Implementationen weiterentwickeln.

% VM Properties and benefits: Was für Nutzen hat VM?
% Fazit: VM hat sehr nützliche Eigenschaften
% More: jacob1998virtualissues

% -------------------------------------------------------------------------------------------------
%                                IMPLEMENTATION OF VIRTUAL MEMORY
% -------------------------------------------------------------------------------------------------

% Wie können wir VM realisieren? -> Verschiedene Implementationen, Aber hier nicht auf die HW eingehen
%   [ A look at several...]
%   [ Issues of implementation]
\subsection{Implementation of Virtual Memory}
Every virtual memory system has to realize a mapping from virtual addresses of each processes
private, virtual address space to physical addresses that index data in main memory.
This section will provide an overview of how most commonly used virtual memory implementation.\\

% Naive approache
The naive approache is to simply have a big array in main memory. This array can be indexed
using the virtual addresses, at which the physical address to that virtual address is placed.\\
In a 32 bit address space with 4 KB pages, this requires 20 bits per page table entry. This
adds up to \[ 20 * 2^{20} bit = 20971520 / 8 Byte = 2.5 MB \].
To properly isolate the processes from each other, every process needs to have one of those arrays.
To realize fine-grained protection of pages, there would also need to be some bits per array entry
for read/write/execute rights.\\
With 64 bit computer, the space requirements for such page tables would be even higher.

% Hierarchical
\subsubsection{Hierarchical page tables} \todo{Different names -> from the survey papers
[a look at several issues of impl], Radix Tree}
To reduce the memory cost of managing pages, most \todo{cite?} virtual memory systems use a
multi-level page table, also known as a hierarchical page table. However, its structure is less like a
is less like a table and more like a tree, where the nodes are tables of page table entries (PTEs).
Here the virtual page number is divided into several parts. Each part of the VPN (Virtual Page Number)
is used to index a smaller table. The indexed PTE then points to the next smaller page table,
which in turn is indexed by the next part of the VPN. Depending on the implementation
this can involve up to 5 further indirections. A common scheme, as specified in the RISC-V ISA,
is Sv39, which provides a total of 3 levels per page table tree\cite{riscvreader}.
This scheme is also shown in the figure \ref{fig:fund}.

\begin{figure*}[t]
    \centering
    \includegraphics[scale=.8]{figures/VM-Tree.pdf}
    \caption[RISC-V Sv39 3-Level Page Tree]{Three-step page walk with a RISC-V Sv39 Page Table Tree:
        The value in the \texttt{satp} register is the base of the root page table; \texttt{VPN[2]}
        is the index into the root page table; the indexed \texttt{PTE} points to the next page table.
        This traversal continues until the bottom of the page table is reached. The last \texttt{PTE}
        contains the \texttt{PPN} of the physical address which can then be combined with the offset
        bits to make the full physical address}
    \label{fig:fund:pagetree}
\end{figure*}

% USE DEEPL WRITE FOR ALL FOLLOWING

% Conclusion -> Many main memory accesses -> Expensive
Traversing the page table to find the mapping requires an additional memory reference for each
level\todo{cite}, and since finding the mapping is on the critical path of every memory operation,
in the worst case, if all caches are missed, up to 5 memory accesses may be required (in a 5-level paging
scheme) just to find the mapping for a single memory access.

% Solution? Hashed!
\subsubsection{Inverted page tables}
An alternative paging scheme approaches the problem from the opposite direction and provides a PTE
for each physical frame instead of one entry per theoretical virtual page.
A physical page frame is a page-aligned space in physical memory for a page.
So the number of physical frames is determined by the size of main memory divided by the page size.
\todo{Pages already defined? Variable size too?}.
This has the enormous advantage, especially for 64-bit address spaces, that only as many pages need to be
as physically exist.
The page table design also has the advantage that, in the best case, significantly fewer main memory
accesses are required. In the simple design shown in figure \ref{fig:fund}, the corresponding
page table entry can be found with just two memory lookups \cite{skarlatos2020elastic}.

% yyWorst case -> Collision count limited only by page frame number
However, as the page frame indices are calculated by the VPN using a hash function, collisions may occur,
hash collisions can occur. Since the length of a collision chain is unpredictable, the maximum number of memory
of memory accesses required to find the correct PTE is only limited by the maximum number of
page frames and therefore by the size of the main memory.

% Hierarchical -> fixed number of refs (but memory usage)
Hierarchical multi-level page tables have the key advantage that they always require
a fixed number of memory accesses to determine the PTE.

% Hash anchor to reduce the number of collisions
Typical inverted page table designs often include a so-called hash anchor table, which is placed between the output of the
between the output of the hash function and the page table. If the hash anchor is twice the size of the
of the page table, the average collision chain length can be halved.
However, at least one additional memory reference is required in any case \cite{jacob1998virtualissues}.
Alternative designs for inverted page tables allow the table to be dynamically resized to avoid hash collisions.
hash collisions. However, this is very expensive and is generally avoided \cite{skarlatos2020elastic}.

% Inverted Page Table figure
\begin{figure*}[t]
    \centering
    \includegraphics[scale=1]{figures/inverted_pt.pdf}
    \caption[Simple Inverted Page Table Design]{A inverted page table has an entry for every physical
        page frame, reducing memory accesses to a minimum of one. Collisions in the hash table (red arrows) can
        make the access much more expensive. }
    \label{fig:fund:inverted}
\end{figure*}

% Conclusion -> Disadvantages of inverted page tables [see also hash don’t cache!]
Inverted page tables significantly reduce the average access time to the PTEs, but they make it
more difficult to support other features like superpages and memory sharing.
The Power Architecture, for example, supports this through a two-stage translation process \cite{yaniv2016hash}.
% [hash dont cache] -> Hashed paging performs better


% [hash dont cache] -> superpages are harder

% [issues of impl] ->

% [ A look at several] ->

% -> Most commonly used in today's hardware -> Multi level page tables
There is no clear winner in the debate between hashed vs. radix \todo{still need to introduce the term "radix"}
and commercial hardware supports a variety of designs that are not standardized and, in some cases,
differ significantly \cite{jacob1998look}.


Modern Intel processors now support radix designs with a depth of up to 5 levels,
which still use 4KB pages to maintain compatibility.

% Todo, aber größere pages erhöhen tlb reach usw
% Fazit -> Hauptproblem von VM sind teure Hauptspeicherzugriffe im kritischen Pfade von allen Memory Operations

\todo{discussion: Sind die aktuellen VM systeme (vor allem hierachical) noch Zeitgemäß oder nur noch altlast???}
% -------------------------------------------------------------------------------------------------
%                                  END SECTION - VM IMPLEMENTATION
% -------------------------------------------------------------------------------------------------



% -------------------------------------------------------------------------------------------------
%                                            VM HARDWARE
% -------------------------------------------------------------------------------------------------
\cite{denning1970virtual} % Hardware support source
\section{Memory Management Hardware}
To further accelerate the translation of virtual to physical addresses, most modern computers use additional
hardware components. These consist of a hardware page table walker (MMU) and a translation cache,
commonly referred to as a Translation Lookaside Buffer (TLB) \cite{jacobVirtualMemoryContemporary1998}.

% Frage: Besteht das MMU aus TLB + State Walker oder ist MMU der State Walker und TLB einfach extra?
% FIGURE Simple HW Architecture for VM Acceleration Hardware
\begin{figure*}[t]
    \centering
    \includegraphics[scale=1.2]{figures/simple_mmu_arch.pdf}
    \caption[A simplified architecture of CPU, MMU and TLB]{A simplified architecture of CPU, MMU and TLB:
        User-level programs running on the \texttt{CPU} try to access main memory with virtual
        addresses; virtual addresses get transparently translated to physical addresses by the
        \texttt{MMU} by either looking up the address in the TLB or by performing a page table
        lookup with the hardware-supported page table design}
    \label{fig:fund:simplearch}
\end{figure*}
% End Figure

% -------------------------------------------------------------------------------------------------

% Davor sollte der Page Table walk bekannt sein
\subsection{MMU}
The Memory Management Unit (MMU) takes on the task of address translation for the computer.
It sits between the processor, which primarily works with virtual addresses, and the memory bus,
which is accessed with physical addresses. When the processor accesses a certain virtual address,
the MMU performs a page table walk to determine the physical address corresponding to the virtual
address. During this process, the processor is effectively frozen \cite{jacobVirtualMemoryContemporary1998}
\todo{more fine-grained citation? -> Probably not, these are only fundamentals, should however quote overarching works}

\subsection{TLB}
Since it would be very costly to traverse the page table in hardware for every load or store memory access,
there is a cache for the translations, the Translation Lookaside Buffer (TLB). This cache contains
the most recent translations from virtual to physical addresses.\\
The MMU can first check the TLB, which can be searched in parallel and thus extremely quickly \cite{drepper2007every}.



% Gute quelle für alles hier : [jacob2010memory]
\cite{jacobVirtualMemoryContemporary1998}
% \subsection{A typical Page Table Walk}

% -------------------------------------------------------------------------------------------------
\subsection{PWCs}
\cite{barrTranslationCachingSkip}
\cite{yaniv2016hash}

% -------------------------------------------------------------------------------------------------
\subsection{Address Space Identifies}
% \cite{jacobSoftwaremanagedAddressTranslation1997}
%TODO in the vm requirements , ASIDs are presented as HW-support for address space protection
With Address Space Identifiers (ASIDs), RISC-V provides a way to more efficiently utilize virtual memory:
Since every process has its own virtual address space, translations that are still present in the
TLB may not be valid after a context switch.\\

\textbf{SFENCE.VMA} RISC-V provides one instruction that acts primarily as a memory barrier:
It prevents reordering of instructions accessing memory accross the \texttt{sfence.vma} instruction.\\
This is important when the page tables are switched, e.g. when the kernel is entered from user mode,
because the translations will change.\\
The instruction also acts as a flushing operation for TLB entries. With both of the optional registers
arguments set to zero, the instruction will flush all entries.\\
Setting the first register to a specific address will only flush translations containing that address.\\
The second register specifies the address space that should be flushed, given a ASID.

This mechanism allows for a precise control over flushing of TLB entries, which can improve the
memory system performance \cite{RISCVInstructionSet}.



% -------------------------------------------------------------------------------------------------


% Fazit -> Es gibt hardware strukturen die VM beschleunigen können, die machen es auch schneller
%       ABER: Die machen die VM Software Systeme auch sehr viel rigider und unflexibler
% Kurze Diskussion -> Machen Hardware strukture das wirklich schneller? [ A look at ...]



% -------------------------------------------------------------------------------------------------

% -------------------------------------------------------------------------------------------------

\section{Sofware-based Virtual Memory System}
% VM in Software möglich mit ähnlicher Performance wie hw möglich -> Sollte ja mehr Flexibilität geben
%   [ A look at several...]
% Software managed address translation
% \subsection{Guarded Page Tables}






% -------------------------------------------------------------------------------------------------
% -------------------------------------------------------------------------------------------------
\section{HW VM vs SW VM}
% related work will then come in to discuss approaches close to my approach
% With only software ptw process would have to context switch to the kernel -> Very expensive
% With an MMU the processor essentially just freezes until the memory operation has completed
% \subsection{HW-Dependent PTE Structure} -> inflexibility
There are several considerations that should be taken into account when comparing hardware and
software-managed translations.

\paragraph{Fixed Paging Structures} In hardware-managed virtual memory, the structures for page tables
and page table entries are fixed by the microarchitecture. As a result, the operating system cannot tailor
memory management to its purposes and use case, and it is stuck with the fixed design.
This also complicates the portability of system software, as there is no standard for these memory management
structures. Despite there being no significant performance differences among the various designs,
there is no standardization \cite{jacob1998look}.

\paragraph{Pipeline Freezing / Flushing} On a TLB miss \todo{already defined?},
with a hardware-managed TLB, only the pipeline freezes (at least for instructions dependent on
the memory access). However, with a software-managed TLB, control is handed back to the operating system
via an exception, which notes that the required address is not in the TLB (TLB miss exception).
The jump back to the operating system causes a context switch, requiring the state of the current process
to be saved. During this, the reorder buffer is flushed, and the pipeline is heavily disrupted.
Switching to the kernel can also lead to further data and instruction misses in the long term,
as the kernel entry likely overwrites some cache lines that the running process needed. \todo{Cite}

\paragraph{Embedded} Using virtual memory is becoming increasingly relevant for embedded systems.
They would certainly benefit from more flexible designs. Additionally, saving on chip size by
eliminating the MMU would also reduce production costs \cite{jacob1998look}. \todo{not sure about this}



% Conclusion of HW vs SW
\cite{jacob1998look} concludes in a comparative study of various HW and SW memory designs
that hardware-based approaches are generally more performant, but software-based designs are certainly
viable if the caches are large enough to reduce the number of cache misses.
Especially in terms of flexibility, software-based approaches have a significant advantage,
as the VM system can be fully defined by the operating system.

% -------------------------------------------------------------------------------------------------

% -------------------------------------------------------------------------------------------------

% TODO Short discussion hw and sw vm -> common problem: Page Table Walks require in either case a
% lot of memory references. These costs can be aleviated using caches, but will still cost [ cite a source abouts costs here]

\todo{section on basic operating system structures like exception handler, load store sandwich}

\todo{fundamentals on the implementation platform}
% -------------------------------------------------------------------------------------------------

% -------------------------------------------------------------------------------------------------


\section{RISC-V Basics}
The implementation presented in this work runs on a RISC-V platform. Therefore, it is necessary
to go over some basic concepts of the RISC-V platform. Particularly relevant here are the virtual
memory system, the exception/trap mechanism, and the control and status registers (CSRs), which
form the foundation for extending RISC-V.

% -------------------------------------------------------------------------------------------------

\subsection{Sv39 Virtual Memory}
\label{fund:sv39}

\todo{explain why the top bits in PTE are all zero (with leichten Bezug zu xv6 impl)}
\begin{figure*}[h!]
    \centering
    \begin{bytefield}[bitwidth=\widefigurewidth/64,bitheight=\widthof{~PBMT~}, bitformatting={\tiny\bfseries}, boxformatting={\centering}]{64}
        \bitheader[endianness=big]{63,62,61,60,54,53,28,27,19,18,10,9,8,7,6,5,4,3,2,1,0} \\
        \bitbox{1}{N} &
        \bitbox{2}{\rotatebox{90}{PBMT}} &
        \bitbox{7}{Reserved} &
        \bitbox{26}{PPN[2]} &
        \bitbox{9}{PPN[1]} &
        \bitbox{9}{PPN[0]} &
        \bitbox{2}{\rotatebox{90}{RSW}} &
        \bitbox{1}{D} &
        \bitbox{1}{A} &
        \bitbox{1}{G} &
        \bitbox{1}{U} &
        \bitbox{1}{X} &
        \bitbox{1}{W} &
        \bitbox{1}{R} &
        \bitbox{1}{V}
    \end{bytefield}
    \caption[RISC-V Sv39 Page Table Entry]{RISC-V Sv39 Page Table Entry}
    \label{fig:theory:sv39pte}
\end{figure*}
% -------------------------------------------------------------------------------------------------

\subsection{Traps}
\todo{Should this be in fundamentals?}
% exceptions vs interrupts
Traps are part of the RISC-V privileged architecture. They provide a mechanism to respond to
external events and unusual runtime events, known as exceptions \cite{riscvreader}.
The term "trap" is an umbrella term that is further divided into interrupts — asynchronous events —
and exceptions — synchronous events.\\
Exceptions are particularly of interest here, as a TLB miss occurs during the execution of an instruction,
meaning it happens synchronously with the processor's clock. However, it is also important to keep interrupts
in mind when working with Qemu and xv6 source code, because on one hand, the Qemu code handles exceptions
and interrupts within the same functions, and on the other hand, xv6, or RISC-V in general, uses a unified
vector for handling both interrupts and exceptions \cite{RISCVInstructionSet}.\\

% Exception registers
There are six central registers for triggering and handling exceptions. These exist both for
Supervisor Mode (prefixed with "s") and Machine Mode (prefixed with "m").
\todo{Have privilege modes been introduced already?}
Whether the machine mode or supervisor mode version of the register should be used for an exception depends
on the mode in which the exception is handled. In the following, all registers are presented with the
M-Mode prefix only \todo{Has M-Mode as an abbreviation for Machine Mode been introduced?}.
\todo{Because the exception was ultimately designed as an M-Mode exception?}

% TODO: sorting of registers by role?

% Vector -> mtvec
\textbf{Exception Vector} The hart \todo{Has the term "hart" been introduced?} experiencing
an exceptional state must know where the kernel routine is located to handle the exception.
The \texttt{BASE} field of the register contains a 4-byte aligned physical address to which
the program counter is set in the case of an exception.\\
The \texttt{MODE} field allows switching between \texttt{direct} and \texttt{vectored} modes.
In \texttt{MODE=Direct}, the PC is set to BASE for all traps, whereas in \texttt{MODE=Vectored},
the PC is set to $BASE+4*CAUSE$ for asynchronous interrupts.\\

% Delegation -> medeleg

% Data for exception handling -> mcause, mtval, mepc, mscratch
\textbf{Context Information} To properly handle the exception, some context information is required.
The \textbf{mcause} register contains the exception code of the exception; \textbf{mepc} contains
the program counter of the instruction that triggered the exception; and \textbf{mtval} holds
exception-specific information, such as the virtual address that triggered a page fault exception.
\textbf{mstatus} contains general information about the current hardware state.\\

\textbf{Delegation} Normally, all exceptions are handled in machine mode; however, in some cases,
it may be useful to handle the exception in a lower privilege mode. With the bitfield in the
\textbf{medeleg} register, individual exceptions can be chosen to be delegated to the next-lower
privilege mode.\\

% Exception number
\textbf{Exception Code} Each exception is assigned a unique number, the exception code \cite{riscvreader}.
This can be found in the \texttt{mcause} register when handling the exception.


% Zusammenspiel der Register im Exception Fall -> xv6 Book Exception Machinery

\textbf{What the Hardware does} Wenn eine Exception getriggert wird macht die Hardware folgendes:
\begin{enumerate}
    \item Interrupts are disabled by clearing the MIE bit in \textbf{mstatus}
    \item PC is copied to mepc
    \item the current mode is saved to the MPP field in mstatus
    \item mcause is set to the proper exception code
    \item the mode is set to the machine mode
    \item Pc is set to stvec
    \item execution continues at the new pc
\end{enumerate}
% -------------------------------------------------------------------------------------------------

\subsection{Contol and Status Registers}
% Section describing RISC-V CSRs -> Originally in theory
\todo{table of csr space in appendix?}
The RISC-V ISA provides a 12-bit encoding space for 4096 CSRs. A CSR address is logically split
into four parts: The top two bits \texttt{csr[11:10]} specify whether the CSR is read/write or read-only;
\texttt{csr[9:8]} encode the minimum priviledge level that is allowed to access the CSR; \texttt{csr[7:4]}
may be partially used to define a specific use for a range of CSRs. E.g. CSRs with an address
between \texttt{0x7B0} and \texttt{0x7BF} shall be used for Debug-mode-only CSRs. The format
of the CSR addresses is also depicted in figure \ref{fig:theory:csr}.

% RISC-V CSR address bytefield
\begin{figure*}[h!]
    \centering
    \begin{bytefield}[bitwidth={2em}, bitformatting={\bfseries}, boxformatting={\centering}]{12}
        \bitheader[endianness=big]{11,10,9,8,7,4,3,0} \\
        \bitbox{2}{RW/RO} &
        \bitbox{2}{Priv} &
        \bitbox{4}{Usage} &
        \bitbox{4}{Index}
    \end{bytefield}
    \caption[RISC-V CSR address format]{RISC-V CSR address format}
    \label{fig:theory:csr}
\end{figure*}

Each legal CSR address identifies a CSR. The size of the CSRs identified by the CSR address depends
on the values of the SXLEN and UXLEN fields in the \textbf{mstatus} register. Currently, the
specification \cite{RISCVInstructionSet} allows for 32 bit, 64 bit and 128 bit.\\ \todo{disclaimer which we will be using here?}
% Short elaboration on using the csr to write TLB entries -> in the end its on the hardware implementor
RISC-V provides dedicated instructions for read/write and bit manipulation with both register values
and immediates.
\todo{ hardware overhead for writing TLB with CSRs -> future work, is it worth it??}

% What format, how big, how many csrs?
Now with CSRs we have a mechanism to add custom behaviour to the ISA. That answers the ''How?''
of writing TLB entries in software.\\
The next step is to figure out what data is required to create a TLB entry and in what format
this data is best communicated via the CSRs to the computer.\\
% -------------------------------------------------------------------------------------------------






% All approaches are based on a table.
% Überleitung zu meinem Thema -> Avoid all memory references and just have a simple (hash?) function that realizes VM
% [ a look at severeal ] -> conlsion


\begin{figure*}[t]
    \centering
    \begin{bytefield}[bitwidth=\widefigurewidth/56,bitheight=\widthof{~PBMT~}, bitformatting={\tiny\bfseries}, boxformatting={\centering}]{56}
        \bitheader[endianness=big]{55,30,29,21,20,12,11,0} \\
        \bitbox{26}{PPN[2]} &
        \bitbox{9}{PPN[1]} &
        \bitbox{9}{PPN[0]} &
        \bitbox{12}{Page Offset}\\
    \end{bytefield}
    \caption[RISC-V Sv39 Physical Address]{RISC-V Sv39 Physical Address}
    \label{fig:theory:sv39pa}
\end{figure*}


\begin{figure*}[t]
    \centering
    \begin{bytefield}[bitwidth=\widefigurewidth/64,bitheight=\widthof{~PBMT~}, bitformatting={\tiny\bfseries}, boxformatting={\centering}]{64}
        \bitheader[endianness=big]{63,60,59,44,43,0} \\
        \bitbox{4}{Mode} &
        \bitbox{16}{ASID} &
        \bitbox{44}{PPN} \\
    \end{bytefield}
    \caption[RISC-V Sv39 \texttt{satp} CSR]{RISC-V Sv39 \texttt{satp} CSR}
    \label{fig:theory:sv39satp}
\end{figure*}

\begin{figure*}[t]
    \centering
    \begin{bytefield}[bitwidth=\widefigurewidth/39,bitheight=\widthof{~PBMT~}, bitformatting={\tiny\bfseries}, boxformatting={\centering}]{39}
        \bitheader[endianness=big]{38,30,29,21,20,12,11,0} \\
        \bitbox{9}{VPN[2]} &
        \bitbox{9}{VPN[1]} &
        \bitbox{9}{VPN[0]} &
        \bitbox{12}{Page Offset}\\
    \end{bytefield}
    \caption[RISC-V Sv39 Virtual Address]{RISC-V Sv39 Virtual Address}
    \label{fig:theory:sv39va}
\end{figure*}
